{
 "cells": [
  {
   "cell_type": "raw",
   "id": "097b868e",
   "metadata": {},
   "source": [
    "conda amazonei tensorflow_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed46e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: folium in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (0.12.1.post1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from folium) (1.19.5)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from folium) (2.26.0)\n",
      "Requirement already satisfied: branca>=0.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from folium) (0.4.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from folium) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from jinja2>=2.9->folium) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests->folium) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests->folium) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests->folium) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests->folium) (3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install folium\n",
    "import folium\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0128deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(_input_dir, _data_size=-1):\n",
    "    \"\"\"\n",
    "    :param _input_dir: input directory name\n",
    "                      AWS S3 directory name, where the input files are stored\n",
    "    :param _data_size: size of data\n",
    "                      Data size, that needs to be tested, by default it takes value of\n",
    "                      -1, which means consider all the data\n",
    "    :return:\n",
    "            the demand data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    # load all the data\n",
    "    months = [\"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\"]\n",
    "    file_format = \"uber-processed-data-{}14.csv\"\n",
    "    _data = DataFrame()\n",
    "    for month in months:\n",
    "        file_name = _input_dir + \"/\" + file_format.format(month)\n",
    "        df_sub = pd.read_csv(file_name)\n",
    "        _data = _data.append(df_sub)\n",
    "\n",
    "    # sample the data\n",
    "    if _data_size > 0:\n",
    "        _data = _data.sample(n=_data_size)\n",
    "\n",
    "    _demand_wh = (_data.groupby(['zip', 'weekday', 'hour']).count()['Date/Time']).reset_index()\n",
    "    _demand_wh.columns = ['Zip', 'Weekday', 'Hour', 'Number of Trips']\n",
    "\n",
    "    return _demand_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1156ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import s3fs\n",
    "import json\n",
    "import boto3 \n",
    "\n",
    "def visualize_demand(_input_bucket, _data_size, _weekdays, _hours):\n",
    "    # generate demand data\n",
    "    demand_wh = load_data(\n",
    "        _input_dir=f\"s3://{_input_bucket}\", _data_size=_data_size,\n",
    "    )\n",
    "    \n",
    "    _weekday_key = \"\".join([str(_w) for _w in _weekdays])\n",
    "    _hour_key = \"\".join([str(_h) for _h in _hours])\n",
    "    \n",
    "    # filterout the weekdays\n",
    "    missing_weekdays = list(set([_w for _w in range(7)]).symmetric_difference(_weekdays))\n",
    "    for m_weekday in missing_weekdays:\n",
    "        demand_wh = demand_wh[demand_wh[\"Weekday\"] != m_weekday]\n",
    "    \n",
    "    # filterout the hour\n",
    "    missing_hours = list(set([_h for _h in range(24)]).symmetric_difference(_hours))\n",
    "    for m_hour in missing_hours:\n",
    "        demand_wh = demand_wh[demand_wh[\"Hour\"] != m_hour]\n",
    "\n",
    "    # load the initial geojson data for NEWYORK\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_object = s3.Object(_input_bucket, 'nyc.geojson')\n",
    "    json_input_data = s3_object.get()['Body'].read().decode('utf-8')\n",
    "    geo_data = json.loads(json_input_data)\n",
    "\n",
    "    # filterout the geojson data for zip from our dataset\n",
    "    geozips = []\n",
    "    for i in range(len(geo_data['features'])):\n",
    "        if int(geo_data['features'][i]['properties']['postalCode']) in list(demand_wh['Zip'].unique()):\n",
    "            geo_data[\"features\"][i]['properties']['postalCode'] = int(geo_data[\"features\"][i]['properties']['postalCode'])\n",
    "            geozips.append(geo_data['features'][i])\n",
    "\n",
    "    updated_json = dict.fromkeys(['type','features'])\n",
    "    updated_json['type'] = 'FeatureCollection'\n",
    "    updated_json['features'] = geozips\n",
    "\n",
    "    # store the updated json to s3 bucket\n",
    "    _updated_bucket = _input_bucket + \"-processed-data\"\n",
    "    s3.create_bucket(Bucket=_updated_bucket)\n",
    "    s3object = s3.Object(_input_bucket + \"-processed-data\", 'nyc-updated.json')\n",
    "    s3object.put(\n",
    "        Body=(bytes(json.dumps(updated_json, sort_keys=True, indent=4, separators=(',', ': ')).encode('UTF-8')))\n",
    "    )\n",
    "\n",
    "    # function to create map\n",
    "    def create_map(table, zips, mapped_feature):\n",
    "        \n",
    "        # reading updated json data\n",
    "        s3 = boto3.resource('s3')\n",
    "        s3_object = s3.Object(_updated_bucket, 'nyc-updated.json')\n",
    "        data = s3_object.get()['Body'].read().decode('utf-8')\n",
    "        ny_geo = json.loads(data)\n",
    "\n",
    "        # initializing the map\n",
    "        m = folium.Map(location = [40.7128, -74.0060], zoom_start = 11)\n",
    "        m.choropleth(\n",
    "            geo_data = ny_geo,\n",
    "            fill_opacity = 1,\n",
    "            line_opacity = 0.2,\n",
    "            data = table,\n",
    "            key_on = 'feature.properties.postalCode',\n",
    "            columns = [zips, mapped_feature],\n",
    "            fill_color = 'YlGnBu',\n",
    "            legend_name = (' ').join(mapped_feature.split('_')).title() + ' Across NY'\n",
    "        )\n",
    "        folium.LayerControl().add_to(m)\n",
    "        final_map_file = f\"{mapped_feature}_w{_weekday_key}_h{_hour_key}_map.html\"\n",
    "        m.save(outfile=final_map_file)\n",
    "        \n",
    "        # writing the html file to s3 bucket\n",
    "        with open(final_map_file, 'rb') as f:\n",
    "            _map_bucket = _input_bucket + \"-map-output\"\n",
    "            s3.create_bucket(Bucket=_map_bucket)\n",
    "            s3 = boto3.client('s3')\n",
    "            s3.put_object(Bucket=_map_bucket, Key=final_map_file, Body=f)\n",
    "\n",
    "    create_map(demand_wh, 'Zip', 'Number of Trips')\n",
    "\n",
    "s3_bucket_name = \"cloud-project-x\"\n",
    "\n",
    "# full week\n",
    "visualize_demand(\n",
    "    _input_bucket=s3_bucket_name, _data_size=-1, \n",
    "    _weekdays=[w for w in range(7)], _hours=[h for h in range(24)]\n",
    ")\n",
    "\n",
    "# monday wednesday friday\n",
    "visualize_demand(\n",
    "    _input_bucket=s3_bucket_name, _data_size=-1, \n",
    "    _weekdays=[0, 2, 4], _hours=[h for h in range(24)]\n",
    ")\n",
    "\n",
    "# tuesday thursday\n",
    "visualize_demand(\n",
    "    _input_bucket=s3_bucket_name, _data_size=-1, \n",
    "    _weekdays=[1, 3], _hours=[h for h in range(24)]\n",
    ")\n",
    "\n",
    "# saturday sunday\n",
    "visualize_demand(\n",
    "    _input_bucket=s3_bucket_name, _data_size=-1, \n",
    "    _weekdays=[5, 6], _hours=[h for h in range(24)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42798daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
