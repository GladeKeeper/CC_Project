{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout\n",
    "from tensorflow.keras.models import model_from_json, load_model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "NUM_SAMPLES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initial_process(_input_dir, _output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    :param _input_dir: input directory name\n",
    "                      AWS S3 directory name, where the input files are stored\n",
    "    :param _output_dir: output directory name\n",
    "                      AWS S3 directory name, where the output files are saved\n",
    "    :param _data_size: size of data\n",
    "                      Data size, that needs to be tested, by default it takes value of\n",
    "                      -1, which means consider all the data\n",
    "    :return:\n",
    "            the processed data, and demand data\n",
    "    \"\"\"\n",
    "    import os.path\n",
    "    import pandas as pd\n",
    "    from pandas import DataFrame\n",
    "    from uszipcode import SearchEngine\n",
    "\n",
    "    # to obtain the zip-codes for latitude, longitude values\n",
    "    engine = SearchEngine()\n",
    "\n",
    "    if not os.path.exists(_output_dir):\n",
    "        os.makedirs(_output_dir)\n",
    "    \n",
    "    def get_zip(entry):\n",
    "        return engine.by_coordinates(entry['Lat'], entry['Lon'], radius=10, returns=1)[0].zipcode\n",
    "\n",
    "    def get_zip_codes(df):\n",
    "        zip_codes = []\n",
    "        zip_history = {}\n",
    "        for i, entry in df.iterrows():\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "            if (entry['Lat'], entry['Lon']) in zip_history:\n",
    "                zip_codes.append(zip_history[entry['Lat'], entry['Lon']])\n",
    "            else:\n",
    "                zip_code = get_zip(entry)\n",
    "                zip_history[entry['Lat'], entry['Lon']] = zip_code\n",
    "                zip_codes.append(zip_code)\n",
    "        return zip_codes\n",
    "    \n",
    "    # load all the data\n",
    "    months = [\"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\"]\n",
    "    file_format = \"uber-raw-data-{}14.csv\"\n",
    "    for month in months:\n",
    "        file_name = _input_dir + \"/\" + file_format.format(month)\n",
    "        _data = pd.read_csv(file_name)\n",
    "        print(len(_data))\n",
    "        # obtaining the zip-codes\n",
    "        print(\"obtaining zip for\", month)\n",
    "        _data['zip'] = get_zip_codes(_data)\n",
    "        # process date and time\n",
    "        _data['Date/Time'] = pd.to_datetime(_data['Date/Time'], format='%m/%d/%Y %H:%M:%S')\n",
    "        _data['weekday'] = _data['Date/Time'].dt.dayofweek\n",
    "        _data['hour'] = _data['Date/Time'].dt.hour\n",
    "\n",
    "        # obtaining the zip-codes\n",
    "        _data['zip'] = _data.apply(\n",
    "            lambda row: engine.by_coordinates(row['Lat'], row['Lon'], radius=10)[0].zipcode, axis=1\n",
    "        )\n",
    "        output_file_name = _input_dir + \"/\" + file_format.format(month)\n",
    "        output_file_name = output_file_name.replace(\"raw\", \"processed\")\n",
    "        _data.to_csv(output_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564516\n",
      "obtaining zip for apr\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "initial_process(\"data\", \"output\")\n",
    "end = datetime.now()\n",
    "print(end)\n",
    "print(start)\n",
    "print(f\"initial processing time {(end - start).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}